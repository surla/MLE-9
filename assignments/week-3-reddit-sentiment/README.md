<p align = "center" draggable=‚Äùfalse‚Äù ><img src="https://user-images.githubusercontent.com/37101144/161836199-fdb0219d-0361-4988-bf26-48b0fad160a3.png"
     width="200px"
     height="auto"/>
</p>



# <h1 align="center" id="heading">Sentiment Analysis of Reddit Data using Reddit API</h1>

In this live coding session, we leverage the Python Reddit API Wrapper (`PRAW`) to retrieve data from subreddits on [Reddit](https://www.reddit.com), and perform sentiment analysis using [`pipelines`](https://huggingface.co/docs/transformers/main_classes/pipelines) from [HuggingFace ( ü§ó the GitHub of Machine Learning )](https://techcrunch.com/2022/05/09/hugging-face-reaches-2-billion-valuation-to-build-the-github-of-machine-learning/), powered by [transformer](https://arxiv.org/pdf/1706.03762.pdf).


## ‚òëÔ∏è Objectives
At the end of this session, you will be able to:
- [ ] Know how to work with APIs
- [ ] Feel more comfortable navigating thru documentation, even inspecting the source code
- [ ] Understand what a `pipeline` object is in HuggingFace
- [ ] perform sentiment analysis using `pipeline`
- [ ] Run a python script in command line and get the results
- [ ] Examine the quality of data
- [ ] Understand data lineage


## :hammer_and_wrench: Pre-Assignment

### Setting up your environment üêçüñ•Ô∏è

Create a new Conda environment for sentiment anaylsis (sa). If you already have this environment, continue to the next step.
```console
  conda create -n sa python=3.8 jupyter -y
```
Activate your new environment
```console
  conda activate sa
```

Open the jupyter-notebook
```console
  jupyter-notebook
```

Navigate through the repo in the notebook to find `imports.ipynb` for this week and open it.

Run all of the cells in the notebook.


## Background
Please review the weekly narrative [here](https://great-yamamomo-5c3.notion.site/Week-3-Ensuring-High-Quality-Data-72851d57aaaf4068b60957f7b5e1891c)
